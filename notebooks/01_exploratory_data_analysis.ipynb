{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2235c1",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Project:** AIDD Final Project\n",
    "**Author:** [Your Name]\n",
    "**Date:** November 9, 2025\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668aeba",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495113ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_loader import DataLoader\n",
    "from data_cleaner import DataCleaner\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773007a",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader(data_dir='../data')\n",
    "\n",
    "# Load dataset (modify this to load your actual data)\n",
    "# Example: df = loader.load_csv('your_data.csv')\n",
    "# For demo purposes, we'll use a sample dataset\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('iris')  # Replace with your actual dataset\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf0613",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf25295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicates}\")\n",
    "print(f\"Percentage: {(duplicates / len(df)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826b835",
   "metadata": {},
   "source": [
    "## 4. Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7666a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# Plot distributions\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        if idx < len(axes):\n",
    "            axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "            axes[idx].set_title(f'Distribution of {col}')\n",
    "            axes[idx].set_xlabel(col)\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee69546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "if len(numerical_cols) > 0:\n",
    "    fig, axes = plt.subplots(1, min(3, len(numerical_cols)), figsize=(15, 5))\n",
    "    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols[:3]):\n",
    "        if idx < len(axes):\n",
    "            axes[idx].boxplot(df[col].dropna())\n",
    "            axes[idx].set_title(f'Box Plot: {col}')\n",
    "            axes[idx].set_ylabel(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"\\nCategorical columns: {categorical_cols}\")\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols[:3]:  # Show first 3\n",
    "        print(f\"\\n{col} value counts:\")\n",
    "        print(df[col].value_counts())\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        df[col].value_counts().plot(kind='bar', color='steelblue')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5afdb",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b70f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "if len(numerical_cols) > 1:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = df[numerical_cols].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find highly correlated pairs\n",
    "    print(\"\\nHighly Correlated Pairs (|correlation| > 0.7):\")\n",
    "    high_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr.append((\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    if high_corr:\n",
    "        for col1, col2, corr in high_corr:\n",
    "            print(f\"{col1} <-> {col2}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"No highly correlated pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da62995",
   "metadata": {},
   "source": [
    "## 6. Pairwise Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44072788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot matrix (pairplot) for numerical features\n",
    "if len(numerical_cols) > 1 and len(numerical_cols) <= 5:\n",
    "    # Only plot if we have a reasonable number of columns\n",
    "    target_col = categorical_cols[0] if categorical_cols else None\n",
    "    \n",
    "    if target_col:\n",
    "        sns.pairplot(df, vars=numerical_cols, hue=target_col, diag_kind='hist', \n",
    "                    plot_kws={'alpha': 0.6}, height=2.5)\n",
    "    else:\n",
    "        sns.pairplot(df[numerical_cols], diag_kind='hist', \n",
    "                    plot_kws={'alpha': 0.6}, height=2.5)\n",
    "    \n",
    "    plt.suptitle('Pairwise Relationships', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Pairplot skipped (too many or too few numerical columns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd07baf",
   "metadata": {},
   "source": [
    "## 7. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable (modify 'target' to your actual target column name)\n",
    "# For demo, we'll use the first categorical column as target\n",
    "if categorical_cols:\n",
    "    target_col = categorical_cols[0]  # Change this to your actual target\n",
    "    print(f\"Target Variable: {target_col}\")\n",
    "    print(f\"\\nTarget Distribution:\")\n",
    "    print(df[target_col].value_counts())\n",
    "    print(f\"\\nTarget Proportions:\")\n",
    "    print(df[target_col].value_counts(normalize=True))\n",
    "    \n",
    "    # Visualize target distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Count plot\n",
    "    df[target_col].value_counts().plot(kind='bar', ax=ax1, color='steelblue')\n",
    "    ax1.set_title(f'Target Distribution: {target_col}')\n",
    "    ax1.set_xlabel(target_col)\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Pie chart\n",
    "    df[target_col].value_counts().plot(kind='pie', ax=ax2, autopct='%1.1f%%')\n",
    "    ax2.set_title(f'Target Proportions: {target_col}')\n",
    "    ax2.set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No categorical target variable found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f187a",
   "metadata": {},
   "source": [
    "## 8. Feature vs Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ae3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how features relate to target\n",
    "if categorical_cols and numerical_cols:\n",
    "    target_col = categorical_cols[0]\n",
    "    \n",
    "    # Box plots of features by target\n",
    "    n_features = min(3, len(numerical_cols))\n",
    "    fig, axes = plt.subplots(1, n_features, figsize=(15, 5))\n",
    "    axes = axes.flatten() if n_features > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols[:n_features]):\n",
    "        df.boxplot(column=col, by=target_col, ax=axes[idx])\n",
    "        axes[idx].set_title(f'{col} by {target_col}')\n",
    "        axes[idx].set_xlabel(target_col)\n",
    "        axes[idx].set_ylabel(col)\n",
    "    \n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10938b",
   "metadata": {},
   "source": [
    "## 9. Key Insights and Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c44402",
   "metadata": {},
   "source": [
    "### Summary of Findings:\n",
    "\n",
    "1. **Dataset Overview:**\n",
    "   - Total observations: [Number]\n",
    "   - Total features: [Number]\n",
    "   - Missing values: [Description]\n",
    "\n",
    "2. **Data Quality:**\n",
    "   - Duplicate rows: [Number]\n",
    "   - Outliers detected in: [Columns]\n",
    "   - Data type issues: [If any]\n",
    "\n",
    "3. **Feature Insights:**\n",
    "   - Most important correlations: [List]\n",
    "   - Features with high variance: [List]\n",
    "   - Potential feature engineering opportunities: [Ideas]\n",
    "\n",
    "4. **Target Variable:**\n",
    "   - Distribution: [Balanced/Imbalanced]\n",
    "   - Class proportions: [Details]\n",
    "   - Relationships with features: [Key findings]\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Data cleaning steps needed: [List]\n",
    "   - Feature engineering suggestions: [List]\n",
    "   - Modeling approach recommendations: [Ideas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84260344",
   "metadata": {},
   "source": [
    "## 10. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10b5ad",
   "metadata": {},
   "source": [
    "Based on this EDA, the next steps are:\n",
    "\n",
    "1. **Data Cleaning:**\n",
    "   - Handle missing values\n",
    "   - Remove or cap outliers\n",
    "   - Remove duplicates\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Create interaction features\n",
    "   - Encode categorical variables\n",
    "   - Scale numerical features\n",
    "\n",
    "3. **Model Development:**\n",
    "   - Split data into train/test sets\n",
    "   - Try multiple algorithms\n",
    "   - Perform hyperparameter tuning\n",
    "\n",
    "4. **Model Evaluation:**\n",
    "   - Compare model performance\n",
    "   - Analyze feature importance\n",
    "   - Validate on test set"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
